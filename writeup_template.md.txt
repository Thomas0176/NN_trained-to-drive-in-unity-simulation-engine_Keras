**Behavioral Cloning Project**

The goals / steps of this project are the following:
* Use the simulator to collect data of good driving behavior
* Build, a convolution neural network in Keras that predicts steering angles from images
* Train and validate the model with a training and validation set
* Test that the model successfully drives around track one without leaving the road
* Summarize the results with a written report

---
###Files Submitted & Code Quality

####1. Submission includes all required files and can be used to run the simulator in autonomous mode

My project includes the following files:
* model.py containing the script to create and train the model
* drive.py for driving the car in autonomous mode
* model.h5 containing a trained convolution neural network 
* writeup_report.md or writeup_report.pdf summarizing the results

####2. Submission includes functional code
Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing 
```
python drive.py model_final.h5
```

####3. Submission code is usable and readable

The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.

###Model Architecture and Training Strategy

####1. An appropriate model arcthiecture has been employed

The overall strategy for deriving a model architecture was to use NVIDIAs architecture as described in their paper.
I thought this model might be appropriate because it was successfully deployed before by the team from NVIDIA.

My model starts with a lambda layer which normalizes the data and the mean centers the data around 0
'model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=input_shape))'

Next, I crop each image to get rid of the sky as well as the lower part of image where there is parts of the vehicle. 
So I crop 70 rows pixels from the top of the image and 25 rows pixels from the bottom of the image

Then I add 5 convolution layers (each with a RELU layer after to introduce nonlinearity). This first three use a 5x5 and the last 2 a 3x3 filter respectively. 

The model ends with four fully connected layers with 100,50,10 and then 1 shapes.

Here is the entire model: 
input_shape = (160, 320, 3)
model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=input_shape))

#crop the image
#70 rows pixels from the top of the image
#25 rows pixels from the bottom of the image
#0 columns of pixels from the left of the image
#0 columns of pixels from the right of the image
model.add(Cropping2D(cropping=((70,25),(0,0))))

model.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))
model.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))
model.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))

model.add(Convolution2D(64, 3, 3, activation='relu'))
model.add(Convolution2D(48, 3, 3, activation='relu'))

model.add(Flatten())

model.add(Dense(100))
model.add(Dense(50))
model.add(Dense(10))
model.add(Dense(1))

model.summary()
model.compile(loss='mse', optimizer='adam', metrics=['mse'], lr=0.0001)



####2. Attempts to reduce overfitting in the model

I played around with dropouts layer but since my final model worked without dropout layers I didn't see the need to add any. 

The model was trained and validated on different data sets that I gathered manually through recording:
- driving straight two laps
- 'recovery' data from left and right sides of the street to go back to center
- Counterclockwise loop of the track
- specific recovery data from certain curves (I mainly had issues with the left turn right after the bridge. So I went back and collected specific recovery data just in that turn. It worked really well) 

Lastly I also excluded a lot of training samples where the steering angle was 0 (convertToSteeringTrainImages.ipynb)

I split up the training and validation data into 4/5 and 1/5. I  randomly shuffled the data set.
I used this training data for training the model. The validation set helped determine if the model was over or under fitting.

You can see 'model mean squared error loss for first epoch for model.png' image for Mean Squared Error for my test and validation set.

####3. Model parameter tuning

The model used an adam optimizer. After some tweaking I settled on a learning rate of 0.0001. 
Longer training might have ended up in overfitting of the model to the training set. For me the maximum performance was reached with an epoch of 2.  
I used generators to ensure that I didn't have to load entire training set into memory. 

